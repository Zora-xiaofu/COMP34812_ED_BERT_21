{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8e188501",
      "metadata": {},
      "source": [
        "# Evaluation Script - Solution C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e75c89a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e75c89a",
        "outputId": "9d233519-e5a3-4a4d-f2d3-0245650e84a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Evaluation code - Solution C - BERT\n",
        "\n",
        "# Please install the following libraries before running the code\n",
        "# !pip install torch\n",
        "# !pip install transformers\n",
        "# !pip install pandas\n",
        "# !pip install scikit-learn\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import json\n",
        "import re\n",
        "import torch\n",
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "MAX_LEN = 128\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Text cleaning\n",
        "def clean_text(text):\n",
        "  text = re.sub(r\"can't\\b\", \"cannot\", text)\n",
        "  text = re.sub(r\"won't\\b\", \"will not\", text)\n",
        "  text = re.sub(r\"n't\\b\", \" not\", text)\n",
        "  text = re.sub(r\"'re\\b\", \" are\", text)\n",
        "  text = re.sub(r\"'m\\b\", \" am\", text)\n",
        "  text = re.sub(r\"'ve\\b\", \" have\", text)\n",
        "  text = re.sub(r\"'ll\\b\", \" will\", text)\n",
        "  text = re.sub(r\"'d\\b\", \" would\", text)\n",
        "  text = re.sub(r\"\\b(he|she|it|that|what|who|there|where|why|when)'s\\b\", r\"\\1 is\", text, flags=re.IGNORECASE)\n",
        "  text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"[URL]\", text)\n",
        "  text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "  return text\n",
        "\n",
        "# Custom Dataset class\n",
        "class EDDataset(Dataset):\n",
        "  def __init__(self, texts, labels=None, tokenizer=None):\n",
        "    self.texts = texts\n",
        "    self.labels = labels\n",
        "    self.tokenizer = tokenizer or BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.texts)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    encoding = self.tokenizer(\n",
        "        self.texts[index],\n",
        "        max_length=MAX_LEN,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "    item = {\n",
        "        'input_ids': encoding['input_ids'].squeeze(0),\n",
        "        'attention_mask': encoding['attention_mask'].squeeze(0)\n",
        "    }\n",
        "    if self.labels is not None:\n",
        "      item['labels'] = torch.tensor(self.labels[index], dtype=torch.long)\n",
        "    return item\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e139d238",
      "metadata": {},
      "source": [
        "# Prediction Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FqmWRoKBWpI0",
      "metadata": {
        "id": "FqmWRoKBWpI0"
      },
      "outputs": [],
      "source": [
        "def predict(model, dataloader, device):\n",
        "  model.eval()\n",
        "  all_logits = []\n",
        "  # Turn off gradient tracking to speed up prediction and save memory\n",
        "  with torch.no_grad():\n",
        "    for batch in dataloader:\n",
        "      input_ids = batch['input_ids'].to(device)\n",
        "      attention_mask = batch['attention_mask'].to(device)\n",
        "      outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "      logits = outputs.logits\n",
        "      all_logits.append(logits)\n",
        "  return torch.cat(all_logits, dim=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "abaa8633",
      "metadata": {},
      "source": [
        "# Run Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yRG6NqhRqQ5E",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRG6NqhRqQ5E",
        "outputId": "6259543f-16c9-4bbf-d1ec-14e94fa26c78"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluation Results:\n",
            "Accuracy: 0.8633\n",
            "F1 Score: 0.7740\n",
            "Precision: 0.7135\n",
            "Recall: 0.8457\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "  model_dir = '/content/drive/My Drive/nlu-lab/bert_model'\n",
        "  model_path = os.path.join(model_dir, 'best_model_bert.pt')\n",
        "  best_param_path = os.path.join(model_dir, 'best_params_bert.json')\n",
        "\n",
        "  non_label = '/content/drive/My Drive/nlu-lab/dev-nonlabel.csv'\n",
        "  labelled = '/content/drive/My Drive/nlu-lab/dev.csv'\n",
        "\n",
        "  # Load best hyperparameters\n",
        "  with open(best_param_path, 'r') as f:\n",
        "    params = json.load(f)\n",
        "\n",
        "  # Load the fine-tuned model\n",
        "  model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
        "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "  model.to(device)\n",
        "  model.eval()\n",
        "\n",
        "  # load validation dataset and tokenizer\n",
        "  val_df = pd.read_csv(non_label)\n",
        "  val_df['combined_text'] = (val_df['Claim'] + \" \" + val_df['Evidence']).apply(clean_text)\n",
        "  tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "  # load corrected labelled file\n",
        "  label_df = pd.read_csv(labelled)\n",
        "  gold_labels = label_df['label'].tolist()\n",
        "\n",
        "  val_dataset = EDDataset(val_df['combined_text'].tolist(), gold_labels, tokenizer)\n",
        "  val_loader = DataLoader(val_dataset, batch_size=params['batch_size'], shuffle=False)\n",
        "\n",
        "  # evaluation\n",
        "  val_logits = predict(model, val_loader, device)\n",
        "  val_preds = torch.argmax(val_logits, dim=1).cpu().numpy()\n",
        "\n",
        "  acc = accuracy_score(gold_labels, val_preds)\n",
        "  f1 = f1_score(gold_labels, val_preds)\n",
        "  precision = precision_score(gold_labels, val_preds)\n",
        "  recall = recall_score(gold_labels, val_preds)\n",
        "\n",
        "  print(f\"\\nEvaluation Results:\")\n",
        "  print(f\"Accuracy: {acc:.4f}\")\n",
        "  print(f\"F1 Score: {f1:.4f}\")\n",
        "  print(f\"Precision: {precision:.4f}\")\n",
        "  print(f\"Recall: {recall:.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
